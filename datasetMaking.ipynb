{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adding requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-3.8.3-cp38-cp38-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2 MB 84 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.19.2)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/lib/python3/dist-packages (from gensim) (1.14.0)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-3.0.0.tar.gz (113 kB)\n",
      "\u001b[K     |████████████████████████████████| 113 kB 893 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.18.1\n",
      "  Downloading scipy-1.5.3-cp38-cp38-manylinux1_x86_64.whl (25.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.8 MB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/lib/python3/dist-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-3.0.0-py3-none-any.whl size=107092 sha256=4d478dc52e0c1c0a8be3538f3d46eb12dc1832925504a6620ced768b98fdf4e3\n",
      "  Stored in directory: /root/.cache/pip/wheels/11/73/9a/f91ac1f1816436b16423617c5be5db048697ff152a9c4346f2\n",
      "Successfully built smart-open\n",
      "Installing collected packages: smart-open, scipy, gensim\n",
      "Successfully installed gensim-3.8.3 scipy-1.5.3 smart-open-3.0.0\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.1.4-cp38-cp38-manylinux1_x86_64.whl (9.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.3 MB 104 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas) (2.7.3)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/lib/python3/dist-packages (from pandas) (2019.3)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.1.4\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.5.zip (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 667 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (7.0)\n",
      "Collecting joblib\n",
      "  Downloading joblib-0.17.0-py3-none-any.whl (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading regex-2020.10.28-cp38-cp38-manylinux2010_x86_64.whl (679 kB)\n",
      "\u001b[K     |████████████████████████████████| 679 kB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.51.0-py2.py3-none-any.whl (70 kB)\n",
      "\u001b[K     |████████████████████████████████| 70 kB 647 kB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434676 sha256=068a2e2395ffdbd5280ef69c22876d0b9304b26b561b2f0daa47ccf3dd22d176\n",
      "  Stored in directory: /root/.cache/pip/wheels/ff/d5/7b/f1fb4e1e1603b2f01c2424dd60fbcc50c12ef918bafc44b155\n",
      "Successfully built nltk\n",
      "Installing collected packages: joblib, regex, tqdm, nltk\n",
      "Successfully installed joblib-0.17.0 nltk-3.5 regex-2020.10.28 tqdm-4.51.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install gensim\n",
    "!pip3 install pandas\n",
    "!pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all ready!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"mention_overall_dict.pickle\", \"rb\") as f:\n",
    "    mention_to_entities = pickle.load(f)\n",
    "print (\"all ready!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example of codes which will be use in making data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'class', 'is', 'a', 'blueprint', 'for', 'the', 'object.', 'A class', 'class is', 'is a', 'a blueprint', 'blueprint for', 'for the', 'the object.', 'A class is', 'class is a', 'is a blueprint', 'a blueprint for', 'blueprint for the', 'for the object.', 'A class is a', 'class is a blueprint', 'is a blueprint for', 'a blueprint for the', 'blueprint for the object.', 'A class is a blueprint', 'class is a blueprint for', 'is a blueprint for the', 'a blueprint for the object.', 'A class is a blueprint for', 'class is a blueprint for the', 'is a blueprint for the object.', 'A class is a blueprint for the', 'class is a blueprint for the object.', 'A class is a blueprint for the object.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import everygrams\n",
    "s_words=[ ' '.join(grams) for grams in list(everygrams('A class is a blueprint for the object.'.split()))]\n",
    "print( s_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Toni%20Morrison': 91})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mention_to_entities[\"Toni Morrison\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'John%20Robert%20Morrison': 1,\n",
       "         'Herbert%20Morrison': 1,\n",
       "         'Morrison%2C%20Virginia': 1,\n",
       "         'Morrison%2C%20Illinois': 1,\n",
       "         'Morrison%2C%20Colorado': 9,\n",
       "         'Morrison%20County%2C%20Minnesota': 3,\n",
       "         'Morrison%20%28community%29%2C%20Wisconsin': 1,\n",
       "         'Morrison%2C%20Missouri': 1,\n",
       "         '%23Morrison%20shelter': 1,\n",
       "         'Bruce%20Morrison': 1,\n",
       "         'Morrison%20Bridge': 2,\n",
       "         'Morrison%20Formation': 1,\n",
       "         'Morrison%2C%20OK': 1,\n",
       "         'Morrison%20%28surname%29': 1,\n",
       "         'Morrison%20Government': 1})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mention_to_entities[\"Morrison\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Toni%20%281935%20film%29': 2,\n",
       "         'Antonio%20Mu%C3%B1oz%20G%C3%B3mez': 2,\n",
       "         'Toni%20Adams': 1,\n",
       "         'Toni%20%28footballer%2C%20born%201946%29': 2,\n",
       "         'Toni%20Tennille': 1,\n",
       "         'Toni%20Braxton': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mention_to_entities[\"Toni\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "import json\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import time\n",
    "from urllib.parse import quote\n",
    "from nltk.util import everygrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since beginning: 00:46:32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "file_object = open('results/segment0.txt','a+', encoding='utf-8')\n",
    "\n",
    "start_time = time.time()\n",
    "lineCount=0\n",
    "\n",
    " # iterate over the plain text data we just created\n",
    "with utils.open('enwiki-latest.json.gz', 'rb') as f:\n",
    "     for line in range(70000):\n",
    "#      for line in f:\n",
    "            lineCount+=1;\n",
    "            # segmenting results to batches with size of 100000\n",
    "            # to avoid lost of  all articles for an unexcpected error\n",
    "            if(lineCount%100000==0):\n",
    "                file_object.close()\n",
    "                name=\"segment\"+str(lineCount/100000)+\"\"\n",
    "                file_object = open('results/'+name+'.txt','a+', encoding='utf-8')\n",
    "                \n",
    "            # decode each JSON line into a Python dictionary object (each line is one article)\n",
    "            article = json.loads(next(f))\n",
    "            # each article has:\n",
    "            # title\n",
    "            # inter links\n",
    "            # sections \n",
    "            title=article['title']\n",
    "            p_links= article['interlinks']\n",
    "            all_links_till_here=set()\n",
    "            # link[1] refers to metion of entitiy in text\n",
    "            # link[0] refers to the entity\n",
    "            for link in p_links:\n",
    "                link.append([ ' '.join(grams) for grams in list(everygrams(link[1].split()))])\n",
    "            \n",
    "            for section_text in article['section_texts']:\n",
    "                sentences = sent_tokenize(section_text)\n",
    "                for sentence in sentences:\n",
    "                    entities=set()\n",
    "                    #first try to find entities which are mentioned  by wiki in sentence\n",
    "                    for link in p_links:\n",
    "                        if(link[1] in sentence):\n",
    "                            all_links_till_here.add(link[0])\n",
    "                            entities.add(link[0].replace(' ','_'))\n",
    "                        #try to find entities which arent mentioned  by wiki for avoidance of reputation\n",
    "                        # mention_to_entities contains collection of all entities that are exists for a mention\n",
    "                        for ngram_link in link[2]:\n",
    "                            if(\" \"+ngram_link+\" \" in sentence):\n",
    "                                try:\n",
    "                                    if((quote(link[0])in mention_to_entities[ngram_link]) and (link[0] in all_links_till_here)):\n",
    "                                        entities.add(link[0].replace(' ','_'))\n",
    "                                        all_links_till_here.add(link[0])\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    if(len(entities)>0):\n",
    "                        # writing each triple in a line (from_entity,sentence,to_entities)\n",
    "                        file_object.write(\"from_entity:\"+title+\"\")\n",
    "                        file_object.write('\\n')\n",
    "                        file_object.write(\"sentence:\"+sentence)\n",
    "                        file_object.write('\\n') \n",
    "                        file_object.write(\"to_entities:\"+\",\".join(entities))\n",
    "                        file_object.write('\\n')\n",
    "                        \n",
    "             \n",
    " \n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "since_beginning = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n",
    "print(\"Since beginning: %s\" % (since_beginning))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all ready!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"mention_overall_dict.pickle\", \"rb\") as f:\n",
    "    mention_to_entities = pickle.load(f)\n",
    "print (\"all ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "import json\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import time\n",
    "from urllib.parse import quote\n",
    "from nltk.util import everygrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------ngram_link:--------------\n",
      "Toni\n",
      "----------------sentence:----------------\n",
      "\n",
      "\t    \n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t'''''Beloved''''' is a 1987 novel by the American writer Toni Morrison.\n",
      "----------------checking if  ngram_link in sentence:---------\n",
      "True\n",
      "----------------mention to entity result:-----------------\n",
      "Counter({'Toni%20%281935%20film%29': 2, 'Antonio%20Mu%C3%B1oz%20G%C3%B3mez': 2, 'Toni%20%28footballer%2C%20born%201946%29': 2, 'Toni%20Adams': 1, 'Toni%20Tennille': 1, 'Toni%20Braxton': 1})\n",
      "\n",
      "\n",
      "----------------ngram_link:--------------\n",
      "American\n",
      "----------------sentence:----------------\n",
      "\n",
      "\t    \n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t'''''Beloved''''' is a 1987 novel by the American writer Toni Morrison.\n",
      "----------------checking if  ngram_link in sentence:---------\n",
      "True\n",
      "----------------mention to entity result:-----------------\n",
      "Counter({'United%20States': 7348, 'Americans': 2075, 'United%20States%20of%20America': 297, 'united%20states': 174, 'American%20people': 124, 'American%20Airlines': 84, 'American%20ethnicity': 64, 'American%20English': 53, 'People%20of%20the%20United%20States': 49, 'Americas': 43, 'American%20football': 39, 'US': 25, 'American%20ancestry': 24, 'Cinema%20of%20the%20United%20States': 24, 'American%20Revolution': 23, 'United%20States%20Army': 18, 'American%20League': 18, 'Television%20in%20the%20United%20States': 18, 'Music%20of%20the%20United%20States': 16, 'Cuisine%20of%20the%20United%20States': 15, 'American%20literature': 10, 'American%20comic%20book': 8, 'United%20States%20Navy': 7, 'Culture%20of%20the%20United%20States': 6, 'History%20of%20the%20Philippines%20%281898%E2%80%931946%29': 6, 'Poetry%20of%20the%20United%20States': 6, 'North%20America': 5, 'American%20People': 4, 'American%20culture': 4, 'American%20whiskey': 4, 'Visual%20art%20of%20the%20United%20States': 4, 'American%20television': 4, 'American%20Athletic%20Conference': 4, 'United%20states': 4, 'American%20Motor%20Car%20Company': 4, 'American%20poetry': 4, 'United%20States%20men%27s%20national%20soccer%20team': 4, 'United%20States%20military': 3, 'Military%20of%20the%20United%20States': 3, 'American%20rock': 3, 'American%20Psychiatric%20Association': 3, 'American%20citizen': 3, 'American%20River': 3, 'Continental%20Army': 3, 'Patriot%20%28American%20Revolution%29': 3, 'Federal%20government%20of%20the%20United%20States': 3, 'US%20Navy': 3, 'United%20States%20poetry': 3, 'American%20cuisine': 3, 'radio%20in%20the%20United%20States': 3, 'United%20States%20citizen': 3, 'Radio%20in%20the%20United%20States': 3, 'Episcopal%20Church%20%28United%20States%29': 2, 'American%20Jews': 2, 'United%20States%20Armed%20Forces': 2, 'American%20%28word%29': 2, 'Filipinos%20of%20American%20descent': 2, 'American%20Football%20Conference': 2, 'Thirteen%20Colonies': 2, 'National%20Army%20%28USA%29': 2, 'American%20folk%20music': 2, 'American%20roots%20music': 2, 'American%20%28album%29': 2, 'Native%20American%20%28U.S.%20Census%29': 2, 'Indigenous%20peoples%20of%20the%20Americas': 2, 'Billboard%20Hot%20100': 2, 'American%20occupation%20zone': 2, 'American%20cheese': 2, 'Military%20history%20of%20the%20United%20States%20during%20World%20War%20II': 2, 'History%20of%20the%20Philippines%20%281898-1946%29': 2, 'American%20three-toed%20woodpecker': 2, 'Soccer%20in%20the%20United%20States': 2, 'American%20Division': 2, 'History%20of%20the%20United%20States': 2, 'Independent%20circuit%23Focus%20of%20U.S.%20indies': 2, 'Citizenship%20of%20the%20United%20States': 2, 'Americans%20in%20the%20United%20Kingdom': 2, 'Big%20Brother%20%28U.S.%29': 2, 'Anhinga': 2, 'Criollo%20people': 2, 'American%20University': 2, 'African-American': 2, 'Politics%20of%20the%20United%20States': 2, '4-4-0': 2, 'United%20States%20women%27s%20national%20basketball%20team': 1, 'United%20States%20nationality%20law%23Dual%20citizenship': 1, 'American%20bison': 1, 'American%20imperialism': 1, 'Music%20of%20the%20United%20States%23Rock%2C%20metal%20and%20punk': 1, 'Timberwolf%20Division': 1, 'Indigenous%20languages%20of%20the%20Americas': 1, 'United%20States%20Constitution': 1, 'Native%20peoples%20of%20the%20Americas': 1, 'Economic%20history%20of%20the%20United%20States': 1, 'Hispanic%20America': 1, 'American%20Expeditionary%20Force': 1, 'Communist%20Party%20USA': 1, 'Ethnic%20American': 1, 'United%20States%20Dollar': 1, 'United%20States%20at%20the%201980%20Winter%20Olympics': 1, 'United%20States%20Army%20Air%20Forces': 1, 'United%20States%20armed%20forces': 1, 'United%20States%20at%20the%201948%20Winter%20Olympics': 1, 'Manila%20galleons': 1, 'Apollo%20program': 1, 'Czech%20Americans': 1, 'Vietnam%20War': 1, 'American%20isolationism': 1, 'American%20High%20School%20%28Fremont%2C%20California%29': 1, 'American%20ethnicity%23%26quot%3BAmerican%20ancestry%26quot%3B%20in%20the%20U.S.%20Census': 1, 'Americans%20in%20Japan': 1, 'American%20cinema': 1, 'CONMEBOL': 1, 'Romanian%20American': 1, 'United%20States%20Army%20Pigeon%20Service': 1, 'American%20food': 1, 'United%20States%20men%27s%20national%20ice%20hockey%20team': 1, 'Economy%20of%20the%20USA': 1, 'British%20American': 1, 'American%20University%20Eagles': 1, 'Universities%20in%20the%20United%20States': 1, 'American%20Titanic%20inquiry': 1, 'Formosa%20Expedition': 1, 'Race%20%28United%20States%20Census%29': 1, 'Architecture%20of%20the%20United%20States': 1, 'Penny%20%28United%20States%20coin%29': 1, 'Matched%20grip%23American%20grip': 1, 'Foreign%20policy%20of%20the%20United%20States': 1, 'Whose%20Line%20Is%20It%20Anyway%3F%20%28U.S.%20TV%20series%29': 1, 'History%20of%20professional%20wrestling%20in%20the%20United%20States': 1, 'Live%20Earth%20concert%2C%20New%20York%20City': 1, 'Historical%20Dictionary%20of%20American%20Slang': 1, 'American%20Music%20Hall': 1, 'American%20pop': 1, 'American%20folk%20music%20revival': 1, 'Coupling%20%28U.S.%20TV%20series%29': 1, 'Eagle%20Squadron': 1, 'American%20alligator': 1, 'Television%20of%20the%20United%20States': 1, 'American%20Brazilians': 1, 'United%20States%20and%20weapons%20of%20mass%20destruction': 1, 'M3%20Half-track': 1, 'U.S.A.': 1, 'US%20customary%20units': 1, 'US%20Army': 1, 'American%20Soccer%20Pyramid': 1, 'Filipino%20Americans': 1, 'United%20States%20Army%20Forces%20in%20the%20Far%20East': 1, 'Maps%20of%20American%20ancestries': 1, 'American%20Canoe%20Association': 1, 'American%20Old%20West': 1, 'United%20States%20Army%20Air%20Force': 1, 'US%20soldier': 1, 'Special%20Forces%20%28United%20States%20Army%29': 1, 'Citizenship%20in%20the%20United%20States': 1, 'Copa%20Sudamericana': 1, 'American%20classical%20music': 1, 'North%20American%20Plate': 1, 'American%20Football': 1, 'English%20language': 1, 'U.S': 1, 'Option%20style': 1, 'Flag%20of%20the%20United%20States': 1, 'politics%20of%20the%20United%20States': 1, 'Most%20Extreme%20Elimination%20Challenge': 1, 'American%20Cocker%20Spaniel': 1, 'American%20Kennel%20Club': 1, 'Hong%20Kong%20Americans': 1, 'Western%20Hemisphere': 1, 'Cinema%20of%20United%20States': 1, 'American%20Comedy%20Awards': 1, 'List%20of%20colleges%20and%20universities%20in%20the%20United%20States': 1, 'U.S.%20television%20science%20fiction': 1, 'NTSC': 1, 'Visual%20arts%20of%20the%20United%20States': 1, 'British%20America': 1, 'Canada%E2%80%93United%20States%20border': 1, 'United%20States%20soccer%20league%20system': 1, 'Anarchism%20in%20the%20United%20States': 1, 'Lend-Lease': 1, 'American%20way%20of%20life': 1, 'American%20option': 1, 'American%20school': 1, 'American%20Falls': 1, 'National%20Baseball%20Hall%20of%20Fame%20and%20Museum': 1, 'Scottish%20American': 1, 'Canadian': 1, 'Know%20Nothing': 1, 'American%20comic%20books': 1, 'Science%20and%20technology%20in%20the%20United%20States': 1, 'U.S.%20Open%20%28tennis%29': 1, 'music%20of%20the%20United%20States': 1, 'The%20United%20States%20of%20America': 1, 'Puerto%20Ricans%20in%20the%20United%20States': 1, 'United%20States%20at%20the%202004%20Summer%20Olympics': 1, 'United%20States%20at%20the%201998%20Winter%20Olympics': 1, 'United%20States%20at%20the%201924%20Winter%20Olympics': 1, 'American%20Bison': 1, 'American%20Academy%20of%20Arts%20and%20Sciences': 1, 'United_States': 1, 'American%20citizenship': 1, 'Vogue%20%28magazine%29': 1, 'American%20nationality%20law': 1, 'Life%20on%20Mars%20%28U.S.%20TV%20series%29': 1, 'List%20of%20American%20composers': 1, 'Beaux-Arts%20architecture%23Beaux-Arts%20in%20the%20United%20States': 1, 'U.S.%20Economy': 1, 'American%20Standard%20Version': 1, 'A1%20Team%20USA': 1, 'British%20North%20America': 1, 'cinema%20of%20the%20United%20States': 1, 'The%20Americas': 1, 'American%20revolution': 1, 'Actors%27%20Equity%20Association': 1, '1979%20United%20States%20Grand%20Prix': 1, 'Music%20of%20the%20Americas': 1, 'American%20crocodile': 1, 'American%20Revolutionary%20War': 1, 'Eastern%20Orthodoxy%20in%20North%20America': 1, 'Russian%20American': 1, 'American%20Society%20of%20Cinematographers': 1, 'comic%20book': 1, 'Indian%20American': 1, 'List%20of%20United%20States%20records%20in%20swimming': 1, 'American%20Mathematical%20Society': 1, 'New%20Wave%20of%20American%20Heavy%20Metal': 1, 'American%20Association%20for%20the%20Advancement%20of%20Science': 1, 'American%20and%20British%20English%20spelling%20differences%23Miscellaneous%20spelling%20differences': 1, 'United%20States%20history': 1, 'Armed%20forces%20of%20the%20United%20States': 1, 'Sport%20in%20the%20United%20States': 1, 'American-style%20board%20game': 1, 'United%20states%20of%20America': 1, 'United%20States%20at%20the%201928%20Winter%20Olympics': 1, 'Immigration%20to%20the%20United%20States': 1, 'Military%20history%20of%20the%20United%20States': 1, 'American%20Eagles%20men%27s%20basketball': 1})\n",
      "from_entity:Beloved (novel)\n",
      "\n",
      "\n",
      " sentence:\n",
      "\t    \n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t'''''Beloved''''' is a 1987 novel by the American writer Toni Morrison.\n",
      "\n",
      "\n",
      "to_entities:Toni_Morrison\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------ngram_link:--------------\n",
      "American\n",
      "----------------sentence:----------------\n",
      "Set after the American Civil War, it tells the story of a family of former slaves whose Cincinnati home is haunted by a malevolent spirit.\n",
      "----------------checking if  ngram_link in sentence:---------\n",
      "True\n",
      "----------------mention to entity result:-----------------\n",
      "Counter({'United%20States': 7348, 'Americans': 2075, 'United%20States%20of%20America': 297, 'united%20states': 174, 'American%20people': 124, 'American%20Airlines': 84, 'American%20ethnicity': 64, 'American%20English': 53, 'People%20of%20the%20United%20States': 49, 'Americas': 43, 'American%20football': 39, 'US': 25, 'American%20ancestry': 24, 'Cinema%20of%20the%20United%20States': 24, 'American%20Revolution': 23, 'United%20States%20Army': 18, 'American%20League': 18, 'Television%20in%20the%20United%20States': 18, 'Music%20of%20the%20United%20States': 16, 'Cuisine%20of%20the%20United%20States': 15, 'American%20literature': 10, 'American%20comic%20book': 8, 'United%20States%20Navy': 7, 'Culture%20of%20the%20United%20States': 6, 'History%20of%20the%20Philippines%20%281898%E2%80%931946%29': 6, 'Poetry%20of%20the%20United%20States': 6, 'North%20America': 5, 'American%20People': 4, 'American%20culture': 4, 'American%20whiskey': 4, 'Visual%20art%20of%20the%20United%20States': 4, 'American%20television': 4, 'American%20Athletic%20Conference': 4, 'United%20states': 4, 'American%20Motor%20Car%20Company': 4, 'American%20poetry': 4, 'United%20States%20men%27s%20national%20soccer%20team': 4, 'United%20States%20military': 3, 'Military%20of%20the%20United%20States': 3, 'American%20rock': 3, 'American%20Psychiatric%20Association': 3, 'American%20citizen': 3, 'American%20River': 3, 'Continental%20Army': 3, 'Patriot%20%28American%20Revolution%29': 3, 'Federal%20government%20of%20the%20United%20States': 3, 'US%20Navy': 3, 'United%20States%20poetry': 3, 'American%20cuisine': 3, 'radio%20in%20the%20United%20States': 3, 'United%20States%20citizen': 3, 'Radio%20in%20the%20United%20States': 3, 'Episcopal%20Church%20%28United%20States%29': 2, 'American%20Jews': 2, 'United%20States%20Armed%20Forces': 2, 'American%20%28word%29': 2, 'Filipinos%20of%20American%20descent': 2, 'American%20Football%20Conference': 2, 'Thirteen%20Colonies': 2, 'National%20Army%20%28USA%29': 2, 'American%20folk%20music': 2, 'American%20roots%20music': 2, 'American%20%28album%29': 2, 'Native%20American%20%28U.S.%20Census%29': 2, 'Indigenous%20peoples%20of%20the%20Americas': 2, 'Billboard%20Hot%20100': 2, 'American%20occupation%20zone': 2, 'American%20cheese': 2, 'Military%20history%20of%20the%20United%20States%20during%20World%20War%20II': 2, 'History%20of%20the%20Philippines%20%281898-1946%29': 2, 'American%20three-toed%20woodpecker': 2, 'Soccer%20in%20the%20United%20States': 2, 'American%20Division': 2, 'History%20of%20the%20United%20States': 2, 'Independent%20circuit%23Focus%20of%20U.S.%20indies': 2, 'Citizenship%20of%20the%20United%20States': 2, 'Americans%20in%20the%20United%20Kingdom': 2, 'Big%20Brother%20%28U.S.%29': 2, 'Anhinga': 2, 'Criollo%20people': 2, 'American%20University': 2, 'African-American': 2, 'Politics%20of%20the%20United%20States': 2, '4-4-0': 2, 'United%20States%20women%27s%20national%20basketball%20team': 1, 'United%20States%20nationality%20law%23Dual%20citizenship': 1, 'American%20bison': 1, 'American%20imperialism': 1, 'Music%20of%20the%20United%20States%23Rock%2C%20metal%20and%20punk': 1, 'Timberwolf%20Division': 1, 'Indigenous%20languages%20of%20the%20Americas': 1, 'United%20States%20Constitution': 1, 'Native%20peoples%20of%20the%20Americas': 1, 'Economic%20history%20of%20the%20United%20States': 1, 'Hispanic%20America': 1, 'American%20Expeditionary%20Force': 1, 'Communist%20Party%20USA': 1, 'Ethnic%20American': 1, 'United%20States%20Dollar': 1, 'United%20States%20at%20the%201980%20Winter%20Olympics': 1, 'United%20States%20Army%20Air%20Forces': 1, 'United%20States%20armed%20forces': 1, 'United%20States%20at%20the%201948%20Winter%20Olympics': 1, 'Manila%20galleons': 1, 'Apollo%20program': 1, 'Czech%20Americans': 1, 'Vietnam%20War': 1, 'American%20isolationism': 1, 'American%20High%20School%20%28Fremont%2C%20California%29': 1, 'American%20ethnicity%23%26quot%3BAmerican%20ancestry%26quot%3B%20in%20the%20U.S.%20Census': 1, 'Americans%20in%20Japan': 1, 'American%20cinema': 1, 'CONMEBOL': 1, 'Romanian%20American': 1, 'United%20States%20Army%20Pigeon%20Service': 1, 'American%20food': 1, 'United%20States%20men%27s%20national%20ice%20hockey%20team': 1, 'Economy%20of%20the%20USA': 1, 'British%20American': 1, 'American%20University%20Eagles': 1, 'Universities%20in%20the%20United%20States': 1, 'American%20Titanic%20inquiry': 1, 'Formosa%20Expedition': 1, 'Race%20%28United%20States%20Census%29': 1, 'Architecture%20of%20the%20United%20States': 1, 'Penny%20%28United%20States%20coin%29': 1, 'Matched%20grip%23American%20grip': 1, 'Foreign%20policy%20of%20the%20United%20States': 1, 'Whose%20Line%20Is%20It%20Anyway%3F%20%28U.S.%20TV%20series%29': 1, 'History%20of%20professional%20wrestling%20in%20the%20United%20States': 1, 'Live%20Earth%20concert%2C%20New%20York%20City': 1, 'Historical%20Dictionary%20of%20American%20Slang': 1, 'American%20Music%20Hall': 1, 'American%20pop': 1, 'American%20folk%20music%20revival': 1, 'Coupling%20%28U.S.%20TV%20series%29': 1, 'Eagle%20Squadron': 1, 'American%20alligator': 1, 'Television%20of%20the%20United%20States': 1, 'American%20Brazilians': 1, 'United%20States%20and%20weapons%20of%20mass%20destruction': 1, 'M3%20Half-track': 1, 'U.S.A.': 1, 'US%20customary%20units': 1, 'US%20Army': 1, 'American%20Soccer%20Pyramid': 1, 'Filipino%20Americans': 1, 'United%20States%20Army%20Forces%20in%20the%20Far%20East': 1, 'Maps%20of%20American%20ancestries': 1, 'American%20Canoe%20Association': 1, 'American%20Old%20West': 1, 'United%20States%20Army%20Air%20Force': 1, 'US%20soldier': 1, 'Special%20Forces%20%28United%20States%20Army%29': 1, 'Citizenship%20in%20the%20United%20States': 1, 'Copa%20Sudamericana': 1, 'American%20classical%20music': 1, 'North%20American%20Plate': 1, 'American%20Football': 1, 'English%20language': 1, 'U.S': 1, 'Option%20style': 1, 'Flag%20of%20the%20United%20States': 1, 'politics%20of%20the%20United%20States': 1, 'Most%20Extreme%20Elimination%20Challenge': 1, 'American%20Cocker%20Spaniel': 1, 'American%20Kennel%20Club': 1, 'Hong%20Kong%20Americans': 1, 'Western%20Hemisphere': 1, 'Cinema%20of%20United%20States': 1, 'American%20Comedy%20Awards': 1, 'List%20of%20colleges%20and%20universities%20in%20the%20United%20States': 1, 'U.S.%20television%20science%20fiction': 1, 'NTSC': 1, 'Visual%20arts%20of%20the%20United%20States': 1, 'British%20America': 1, 'Canada%E2%80%93United%20States%20border': 1, 'United%20States%20soccer%20league%20system': 1, 'Anarchism%20in%20the%20United%20States': 1, 'Lend-Lease': 1, 'American%20way%20of%20life': 1, 'American%20option': 1, 'American%20school': 1, 'American%20Falls': 1, 'National%20Baseball%20Hall%20of%20Fame%20and%20Museum': 1, 'Scottish%20American': 1, 'Canadian': 1, 'Know%20Nothing': 1, 'American%20comic%20books': 1, 'Science%20and%20technology%20in%20the%20United%20States': 1, 'U.S.%20Open%20%28tennis%29': 1, 'music%20of%20the%20United%20States': 1, 'The%20United%20States%20of%20America': 1, 'Puerto%20Ricans%20in%20the%20United%20States': 1, 'United%20States%20at%20the%202004%20Summer%20Olympics': 1, 'United%20States%20at%20the%201998%20Winter%20Olympics': 1, 'United%20States%20at%20the%201924%20Winter%20Olympics': 1, 'American%20Bison': 1, 'American%20Academy%20of%20Arts%20and%20Sciences': 1, 'United_States': 1, 'American%20citizenship': 1, 'Vogue%20%28magazine%29': 1, 'American%20nationality%20law': 1, 'Life%20on%20Mars%20%28U.S.%20TV%20series%29': 1, 'List%20of%20American%20composers': 1, 'Beaux-Arts%20architecture%23Beaux-Arts%20in%20the%20United%20States': 1, 'U.S.%20Economy': 1, 'American%20Standard%20Version': 1, 'A1%20Team%20USA': 1, 'British%20North%20America': 1, 'cinema%20of%20the%20United%20States': 1, 'The%20Americas': 1, 'American%20revolution': 1, 'Actors%27%20Equity%20Association': 1, '1979%20United%20States%20Grand%20Prix': 1, 'Music%20of%20the%20Americas': 1, 'American%20crocodile': 1, 'American%20Revolutionary%20War': 1, 'Eastern%20Orthodoxy%20in%20North%20America': 1, 'Russian%20American': 1, 'American%20Society%20of%20Cinematographers': 1, 'comic%20book': 1, 'Indian%20American': 1, 'List%20of%20United%20States%20records%20in%20swimming': 1, 'American%20Mathematical%20Society': 1, 'New%20Wave%20of%20American%20Heavy%20Metal': 1, 'American%20Association%20for%20the%20Advancement%20of%20Science': 1, 'American%20and%20British%20English%20spelling%20differences%23Miscellaneous%20spelling%20differences': 1, 'United%20States%20history': 1, 'Armed%20forces%20of%20the%20United%20States': 1, 'Sport%20in%20the%20United%20States': 1, 'American-style%20board%20game': 1, 'United%20states%20of%20America': 1, 'United%20States%20at%20the%201928%20Winter%20Olympics': 1, 'Immigration%20to%20the%20United%20States': 1, 'Military%20history%20of%20the%20United%20States': 1, 'American%20Eagles%20men%27s%20basketball': 1})\n",
      "\n",
      "\n",
      "----------------ngram_link:--------------\n",
      "Civil\n",
      "----------------sentence:----------------\n",
      "Set after the American Civil War, it tells the story of a family of former slaves whose Cincinnati home is haunted by a malevolent spirit.\n",
      "----------------checking if  ngram_link in sentence:---------\n",
      "True\n",
      "----------------mention to entity result:-----------------\n",
      "Counter({'Civil%20engineering': 7, 'Civil%20Engineering': 4, 'Civil%20law%20%28common%20law%29': 3, 'American%20Civil%20War': 3, 'Civil%20service': 1, 'Civil%20law%20%28legal%20system%29': 1})\n",
      "\n",
      "\n",
      "----------------ngram_link:--------------\n",
      "American Civil\n",
      "----------------sentence:----------------\n",
      "Set after the American Civil War, it tells the story of a family of former slaves whose Cincinnati home is haunted by a malevolent spirit.\n",
      "----------------checking if  ngram_link in sentence:---------\n",
      "True\n",
      "----------------mention to entity result:-----------------\n",
      "Counter({'American%20Civil%20War': 1})\n",
      "\n",
      "\n",
      "----------------ngram_link:--------------\n",
      "Cincinnati\n",
      "----------------sentence:----------------\n",
      "Set after the American Civil War, it tells the story of a family of former slaves whose Cincinnati home is haunted by a malevolent spirit.\n",
      "----------------checking if  ngram_link in sentence:---------\n",
      "True\n",
      "----------------mention to entity result:-----------------\n",
      "Counter({'Cincinnati': 936, 'Cincinnati%2C%20Ohio': 167, 'Cincinnati%20Masters': 24, 'Cincinnati%20Bearcats%20football': 12, 'Cincinnati%20Bearcats%20men%27s%20basketball': 9, 'Cincinnati/Northern%20Kentucky%20International%20Airport': 8, 'Cincinnati%20Reds': 7, 'University%20of%20Cincinnati': 4, 'Great%20American%20Ball%20Park': 3, '1975%20Cincinnati%20Reds%20season': 2, 'Cincinnati-Northern%20Kentucky': 2, 'Western%20%26amp%3B%20Southern%20Financial%20Group%20Masters': 2, 'Roman%20Catholic%20Archdiocese%20of%20Cincinnati': 2, 'Cincinnati%20Bearcats': 2, '2009%20Cincinnati%20Bearcats%20football%20team': 2, 'USS%20Cincinnati%20%28C-7%29': 2, 'Cincinnati%2C%20Iowa': 2, 'Cincinnati%20Bengals': 2, '2014%20Western%20%26amp%3B%20Southern%20Open': 2, '1970%20Cincinnati%20Reds%20season': 2, '2011%20Cincinnati%20Bearcats%20football%20team': 2, '1999%20Cincinnati%20Reds%20season': 2, '2004%20Cincinnati%20Reds%20season': 2, '2011%20Western%20%26amp%3B%20Southern%20Open': 2, '1961%E2%80%9362%20Cincinnati%20Bearcats%20men%27s%20basketball%20team': 2, 'Cincinnati%20%28horse%29': 2, 'Cincinnati%20metropolitan%20area': 2, '2009%20Western%20%26amp%3B%20Southern%20Financial%20Group%20Women%27s%20Open': 2, '1995%20Cincinnati%20Reds%20season': 2, 'Cincinnati%20City%20Hall': 2, '1974%20Cincinnati%20Reds%20season': 1, '2006%20Cincinnati%20Reds%20season': 1, '1981%20Cincinnati%20Reds%20season': 1, '2015%20Western%20%26amp%3B%20Southern%20Open%20%E2%80%93%20Women%27s%20Doubles': 1, 'Paul%20Brown%20Stadium': 1, '1975%20Cincinnati%20Bengals%20season': 1, 'Cincinnati%20Bell%20Connector': 1, 'Cincinnati-Northern%20Kentucky%20International%20Airport': 1, 'Cincinnati%20Northern%20Kentucky%20International%20Airport': 1, 'Western%20%26amp%3B%20Southern%20Financial%20Group%20Women%27s%20Open': 1, '2012%20Western%20%26amp%3B%20Southern%20Open': 1, 'WSTR-TV': 1, 'FC%20Cincinnati%20%282016%E2%80%9318%29': 1, '2018%20Western%20%26amp%3B%20Southern%20Open%20%E2%80%93%20Men%27s%20Singles': 1, '1989%20Cincinnati%20Reds%20season': 1, 'Cincinnati%20Symphony': 1, '2009%20Western%20%26amp%3B%20Southern%20Financial%20Group%20Masters%20%E2%80%93%20Singles': 1, '2002%20Cincinnati%20Bearcats%20football%20team': 1, '1994%20Cincinnati%20Reds%20season': 1, '1998%20Cincinnati%20Reds%20season': 1, 'Roman%20Catholic%20Bishop%20of%20Cincinnati': 1, 'Flag%20of%20Cincinnati': 1, 'Cincinnati%2C%20OH': 1, 'Riverfront%20Stadium': 1, '1977%20Cincinnati%20Reds%20season': 1, 'Cincinnati%20Reds%20%281876%E2%80%9380%29': 1, 'Cincinnati%20Reds%20%281876%E2%80%931880%29': 1, '2015%20Cincinnati%20Bengals%20season': 1, 'The%20Who%20concert%20disaster': 1, 'Eden%20Park': 1, '2008%20Western%20%26amp%3B%20Southern%20Financial%20Group%20Women%27s%20Open': 1, '2010%20Western%20%26amp%3B%20Southern%20Financial%20Group%20Women%27s%20Open': 1, '2005%20Cincinnati%20Bengals%20season': 1, '1979%20Cincinnati%20Bengals%20season': 1, '2016%20Cincinnati%20Reds%20season': 1, 'Cincinnati%20Stingers': 1, '1986%20Cincinnati%20Reds%20season': 1, '2009%20Western%20%26amp%3B%20Southern%20Financial%20Group%20Women%27s%20Open%20%E2%80%93%20Singles': 1, 'Cincinnati%20Car%20Company': 1, '1991%20Cincinnati%20Reds%20season': 1, '2013%E2%80%9314%20Cincinnati%20Bearcats%20men%27s%20basketball%20team': 1, '1981%20Cincinnati%20Bengals%20season': 1, 'Cincinnati%20%28magazine%29': 1, 'https%3A//www.cps-k12.org/about-cps/board-of-education': 1, '2013%20Cincinnati%20Bengals%20season': 1, '2013%20Western%20%26amp%3B%20Southern%20Open': 1, '2015%20Western%20%26amp%3B%20Southern%20Open': 1, '2009%20Cincinnati%20Reds%20season': 1, 'WEBN%20HD3': 1})\n",
      "\n",
      "\n",
      "----------------ngram_link:--------------\n",
      "of\n",
      "----------------sentence:----------------\n",
      "Set after the American Civil War, it tells the story of a family of former slaves whose Cincinnati home is haunted by a malevolent spirit.\n",
      "----------------checking if  ngram_link in sentence:---------\n",
      "True\n",
      "----------------mention to entity result:-----------------\n",
      "Counter({'Hurricane%20Edna': 1, 'United%20Airlines%20Flight%20175': 1, 'territorial%20designation': 1, 'Camilla%2C%20Duchess%20of%20Cornwall': 1, 'Jackson%2C%20Tennessee': 1, 'KEIB': 1, 'List%20of%20Governors%20of%20New%20York': 1, 'List%20of%20United%20States%20Senators%20from%20New%20Mexico': 1})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4354c5187649>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m                     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                         \u001b[0;31m# writing each triple in a line (from_entity,sentence,to_entities)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                         \u001b[0mfile_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"from_entity:\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"from_entity:\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                         \u001b[0mfile_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "file_object = open('dataset-making-example/results-example/Beloved.txt','a+', encoding='utf-8')\n",
    "\n",
    "start_time = time.time()\n",
    "lineCount=0\n",
    "\n",
    " # iterate over the plain text data we just created\n",
    "with utils.open('dataset-making-example/Beloved.json.gz', 'rb') as f:\n",
    "    \n",
    "     for line in range(1):   \n",
    "            # decode each JSON line into a Python dictionary object (each line is one article)\n",
    "            article = json.loads(next(f))\n",
    "            # each article has:\n",
    "            # title\n",
    "            # inter links\n",
    "            # sections \n",
    "            title=article['title']\n",
    "            p_links= article['interlinks']\n",
    "            all_links_till_here=set()\n",
    "            # link[1] refers to metion of entitiy in text\n",
    "            # link[0] refers to the entity\n",
    "            for link in p_links:\n",
    "                link.append([ ' '.join(grams) for grams in list(everygrams(link[1].split()))])\n",
    "            for section_text in article['section_texts']:\n",
    "                sentences = sent_tokenize(section_text)\n",
    "                for sentence in sentences:\n",
    "                    entities=set()\n",
    "                    #first try to find entities which are mentioned  by wiki in sentence\n",
    "                    for link in p_links:\n",
    "                        if(link[1] in sentence):\n",
    "                            all_links_till_here.add(link[0])\n",
    "                            entities.add(link[0].replace(' ','_'))\n",
    "                        #try to find entities which arent mentioned  by wiki for avoidance of reputation\n",
    "                        # mention_to_entities contains collection of all entities that are exists for a mention\n",
    "                        for ngram_link in link[2]:\n",
    "                            if(\" \"+ngram_link+\" \" in sentence):\n",
    "                                print(\"\\n\")\n",
    "                                print(\"----------------ngram_link:--------------\")\n",
    "                                print(ngram_link)\n",
    "                                print(\"----------------sentence:----------------\")\n",
    "                                print(sentence)\n",
    "                                print(\"----------------checking if  ngram_link in sentence:---------\")\n",
    "                                print(ngram_link in sentence)\n",
    "                                try:\n",
    "                                    print(\"----------------mention to entity result:-----------------\")\n",
    "                                    print(mention_to_entities[ngram_link])\n",
    "                                    if((quote(link[0])in mention_to_entities[ngram_link]) and (link[0] in all_links_till_here)):\n",
    "                                        entities.add(link[0].replace(' ','_'))\n",
    "                                        all_links_till_here.add(link[0])\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                    if(len(entities)>0):\n",
    "                        # writing each triple in a line (from_entity,sentence,to_entities)\n",
    "                        file_object.write(\"from_entity:\"+title+\"\")\n",
    "                        print(\"from_entity:\"+title+\"\")\n",
    "                        file_object.write('\\n')\n",
    "                        print('\\n')\n",
    "                        file_object.write(\"sentence:\"+sentence)\n",
    "                        print(\" sentence:\"+sentence)\n",
    "                        file_object.write('\\n') \n",
    "                        print('\\n')\n",
    "                        file_object.write(\"to_entities:\"+\",\".join(entities))\n",
    "                        print(\"to_entities:\"+\",\".join(entities))\n",
    "                        file_object.write('\\n')\n",
    "                        print('\\n')\n",
    "                        file_object.close()\n",
    " \n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "since_beginning = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n",
    "print(\"Since beginning: %s\" % (since_beginning))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
